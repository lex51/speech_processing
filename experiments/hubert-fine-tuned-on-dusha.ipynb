{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/examples-of-calls'):\n    for filename in filenames:\n        pass\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T15:00:12.697258Z","iopub.execute_input":"2023-09-10T15:00:12.697654Z","iopub.status.idle":"2023-09-10T15:00:12.709007Z","shell.execute_reply.started":"2023-09-10T15:00:12.697621Z","shell.execute_reply":"2023-09-10T15:00:12.707790Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"/kaggle/input/examples-of-calls/samples/implantcity.mp3\n/kaggle/input/examples-of-calls/samples/Звонок в техподдержку КорбинаТелеком - Во дает!!)).mp3\n/kaggle/input/examples-of-calls/samples/Звонок в техподдержку - Пьяная мадам.mp3\n/kaggle/input/examples-of-calls/samples/Пранкер - Звонок в техподдержку антивируса Лаборатория Касперского....mp3\n/kaggle/input/examples-of-calls/samples/whiteservice.mp3\n/kaggle/input/examples-of-calls/samples/Звонок в техподдержку Stream - Антон Уральский (Ни единого разрыва!).mp3\n/kaggle/input/examples-of-calls/samples/ЗВОНОК КЛИЕНТА СТРИМА В ТЕХПОДДЕРЖКУ - ВЫ НЕ ОТВЕЧАЕТЕ НА МОЙ ОТВЕТ!!!.mp3\n/kaggle/input/examples-of-calls/samples/Nightmare - Звонок в техподдержку Rambler.mp3\n/kaggle/input/examples-of-calls/samples/79180970824_in_2022_06_04-12_58_30_79184924202_3pqb.mp3\n/kaggle/input/examples-of-calls/samples/Звонок в техподдержку - Матрица xxx твои мозги,прикинь.mp3\n","output_type":"stream"}]},{"cell_type":"code","source":"from glob import glob\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\n\n__import__('warnings').filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:00:12.715576Z","iopub.execute_input":"2023-09-10T15:00:12.716347Z","iopub.status.idle":"2023-09-10T15:00:12.721905Z","shell.execute_reply.started":"2023-09-10T15:00:12.716320Z","shell.execute_reply":"2023-09-10T15:00:12.720944Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\nfrom transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\nimport torchaudio\nimport torch\n\n# Указать устройство (GPU) для вычислений, если оно доступно\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Загрузка модели и экстрактора признаков на устройство GPU\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\nmodel = HubertForSequenceClassification.from_pretrained(\"xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:00:12.736775Z","iopub.execute_input":"2023-09-10T15:00:12.737826Z","iopub.status.idle":"2023-09-10T15:00:18.178458Z","shell.execute_reply.started":"2023-09-10T15:00:12.737794Z","shell.execute_reply":"2023-09-10T15:00:18.177314Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"HubertForSequenceClassification(\n  (hubert): HubertModel(\n    (feature_extractor): HubertFeatureEncoder(\n      (conv_layers): ModuleList(\n        (0): HubertLayerNormConvLayer(\n          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (1-4): 4 x HubertLayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (5-6): 2 x HubertLayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n      )\n    )\n    (feature_projection): HubertFeatureProjection(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (projection): Linear(in_features=512, out_features=1024, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): HubertEncoderStableLayerNorm(\n      (pos_conv_embed): HubertPositionalConvEmbedding(\n        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n        (padding): HubertSamePadLayer()\n        (activation): GELUActivation()\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (layers): ModuleList(\n        (0-23): 24 x HubertEncoderLayerStableLayerNorm(\n          (attention): HubertAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (dropout): Dropout(p=0.1, inplace=False)\n          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (feed_forward): HubertFeedForward(\n            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (output_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (projector): Linear(in_features=1024, out_features=256, bias=True)\n  (classifier): Linear(in_features=256, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"DATASET_PATH = r'/kaggle/input/sample-wavs'\nDATASETS = ['podcast_train', 'podcast_test', 'crowd_test']\nEXAMPLES = Path(r'/kaggle/input/examples-of-calls')\nWORK_PATH = Path('.')\n\nnum2emotion = {0: 'neutral', 1: 'angry', 2: 'positive', 3: 'sad', 4: 'other'}\nemotion2num = {emotion: num for num, emotion in num2emotion.items()}\n\ndataset = DATASETS[-1]\n\ncrowd_test = os.path.join(DATASET_PATH, dataset)\ncrowd_info = os.path.join(crowd_test, f'raw_{dataset}.tsv')","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:00:18.180784Z","iopub.execute_input":"2023-09-10T15:00:18.181148Z","iopub.status.idle":"2023-09-10T15:00:18.189246Z","shell.execute_reply.started":"2023-09-10T15:00:18.181113Z","shell.execute_reply":"2023-09-10T15:00:18.188087Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(crowd_info, sep='\\t')\nprint('Всего строк:', len(df))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:00:18.190480Z","iopub.execute_input":"2023-09-10T15:00:18.191279Z","iopub.status.idle":"2023-09-10T15:00:18.678527Z","shell.execute_reply.started":"2023-09-10T15:00:18.191247Z","shell.execute_reply":"2023-09-10T15:00:18.677396Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Всего строк: 79088\n","output_type":"stream"}]},{"cell_type":"code","source":"check_column = 'annotator_emo'\n# check_column = 'speaker_emo'\n\nif check_column != 'speaker_emo':\n    df[\"speaker_emo\"].fillna(df[\"annotator_emo\"], inplace=True)\nelse:\n    df.dropna(subset=['speaker_emo'], inplace=True)\n\ndf.drop_duplicates(subset=['audio_path', check_column], inplace=True)\nprint('Без дубликатов:', len(df))\n\nif not len(df):\n    print('\\nФАЙЛЫ ДЛЯ ОБРАБОТКИ ОТСУТСТВУЮТ !!!')\n    exit()\n\ntqdm.pandas()\n# Проверка и фильтрация датафрейма\ndf = df[df['audio_path'].progress_apply(lambda x: os.path.isfile(os.path.join(crowd_test, x)))]\nprint('Итого осталось файлов:', len(df))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:00:18.681529Z","iopub.execute_input":"2023-09-10T15:00:18.682289Z","iopub.status.idle":"2023-09-10T15:01:17.707253Z","shell.execute_reply.started":"2023-09-10T15:00:18.682261Z","shell.execute_reply":"2023-09-10T15:01:17.706275Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Без дубликатов: 24616\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/24616 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bdada3d60d94027b6159cf9b463e28d"}},"metadata":{}},{"name":"stdout","text":"Итого осталось файлов: 24616\n","output_type":"stream"}]},{"cell_type":"code","source":"emos = pd.DataFrame(df.groupby('audio_path')[check_column].apply(lambda x: list(x)))\nemos['audio_path'] = emos.index\nemos.reset_index(drop=True, inplace=True)\nemos.columns = ['ann_emos', 'audio_path']\ndf_flt = df.merge(emos, on='audio_path', how='left')\ndf_flt['ann_emos'] = df_flt['ann_emos'].map(lambda x: ' '.join(sorted(x)))\n\n# убираем записи в который эмоция \"angry\" встречается с другими эмоциями\ndf_flt = df_flt[~df_flt['ann_emos'].str.startswith('angry ')]\n# убираем записи в который эмоция \"positive\" встречается с другими эмоциями\ndf_flt = df_flt[~df_flt['ann_emos'].str.contains(' positive')]  # После фильтрации: 9991\ndf_flt = df_flt[~df_flt['ann_emos'].str.contains('positive ')]  # После фильтрации: 9987\nprint('После фильтрации:', len(df_flt))\n\ndf = df_flt","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:01:17.708918Z","iopub.execute_input":"2023-09-10T15:01:17.709569Z","iopub.status.idle":"2023-09-10T15:01:18.394966Z","shell.execute_reply.started":"2023-09-10T15:01:17.709525Z","shell.execute_reply":"2023-09-10T15:01:18.393950Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"После фильтрации: 17986\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntmp = df.iloc[:]\npreds = []\npredicted_probs = []\nfor index, row in tqdm(tmp.iterrows(), total=len(tmp)):\n    file_path = os.path.join(crowd_test, row['audio_path'])\n    \n    waveform, sample_rate = torchaudio.load(file_path, normalize=True)\n    transform = torchaudio.transforms.Resample(sample_rate, 16000)\n    waveform = transform(waveform)\n    \n    # Перенести данные на GPU\n    waveform = waveform.to(device)\n\n    inputs = feature_extractor(\n            waveform, \n            sampling_rate=feature_extractor.sampling_rate, \n            return_tensors=\"pt\",\n            padding=True,\n            max_length=16000 * 10,\n            truncation=True\n        )\n\n    # Перенести данные на GPU\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n\n    logits = model(inputs['input_values'][0]).logits\n    predictions = torch.argmax(logits, dim=-1)\n    # Перенести результаты на CPU\n    pred = predictions.cpu().numpy()[0]\n    predicted_emotion = num2emotion[pred]\n\n    preds.append(predicted_emotion)\n#     print('pred:', predicted_emotion, 'true:', row['annotator_emo'])\n\n    # Преобразование меток классов в вероятности (softmax)\n    softmax = torch.nn.Softmax(dim=1)\n    probabilities = softmax(logits)\n    predicted_probs.append(probabilities.detach().cpu().numpy())\n    \ntmp['pred'] = preds\ntmp['probs'] = predicted_probs\n\ntmp.to_csv(f'preds_hb_{dataset}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:01:18.396400Z","iopub.execute_input":"2023-09-10T15:01:18.396960Z","iopub.status.idle":"2023-09-10T15:18:55.720920Z","shell.execute_reply.started":"2023-09-10T15:01:18.396925Z","shell.execute_reply":"2023-09-10T15:18:55.719841Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17986 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21c99246a92d4bc284b16816b4743bcd"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 15min 6s, sys: 5.99 s, total: 15min 12s\nWall time: 17min 37s\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import display, FileLink\nfrom zipfile import ZipFile, ZIP_DEFLATED as ZD\nfrom glob import glob\n\nfiles = glob(f'{WORK_PATH}/*.csv')\nzip_filename = WORK_PATH.joinpath('predictions.zip')\nwith ZipFile(zip_filename, 'w',  compression=ZD, compresslevel=9) as zip_file:\n    for filename in files:\n        print(filename)\n        zip_file.write(filename)\nFileLink(zip_filename)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:18:55.722543Z","iopub.execute_input":"2023-09-10T15:18:55.723156Z","iopub.status.idle":"2023-09-10T15:18:56.331210Z","shell.execute_reply.started":"2023-09-10T15:18:55.723120Z","shell.execute_reply":"2023-09-10T15:18:56.330320Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"./preds_hb_crowd_test.csv\n./preds_hb_podcast_test.csv\n","output_type":"stream"},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/predictions.zip","text/html":"<a href='predictions.zip' target='_blank'>predictions.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"phb = tmp","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:18:56.464755Z","iopub.execute_input":"2023-09-10T15:18:56.465322Z","iopub.status.idle":"2023-09-10T15:18:56.470315Z","shell.execute_reply.started":"2023-09-10T15:18:56.465289Z","shell.execute_reply":"2023-09-10T15:18:56.469182Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score as F1, classification_report, roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\n\ntst = phb.copy()\n\nremap = {'sad': 'neutral', 'other': 'neutral'}\n\nfor col in ('annotator_emo', 'speaker_emo', 'pred'):\n    tst[col] = tst[col].map(lambda x: remap.get(x, x))\n\nemos = {'5 emo': phb, '3 emo': tst}\ntrue_columns = ('annotator_emo', 'speaker_emo')\n\nfor emo, df in emos.items():\n    for name_col in ('annotator_emo', 'speaker_emo'):\n        # Пример истинных меток и предсказанных вероятностей для многоклассовой классификации\n        # Истинные метки классов\n        y_true = df[name_col].map(emotion2num)  \n        # Предсказанные вероятности для каждого класса\n        y_scores = np.concatenate(df['probs'].values)  \n        # Преобразуем истинные метки классов в бинарный формат\n        lb = LabelBinarizer()\n        y_true_bin = lb.fit_transform(y_true)\n        n_emos = len(lb.classes_)\n        roc_auc = roc_auc_score(y_true_bin, y_scores[:, :n_emos], average=\"macro\") \n        \n        print(f'f1_score ({emo}) по колонке {name_col:<13} =',\n              F1(df[name_col], df['pred'], average='weighted', zero_division=0).round(3),\n             'roc_auc_score = ', roc_auc)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:31:35.568452Z","iopub.execute_input":"2023-09-10T15:31:35.568821Z","iopub.status.idle":"2023-09-10T15:31:36.571026Z","shell.execute_reply.started":"2023-09-10T15:31:35.568793Z","shell.execute_reply":"2023-09-10T15:31:36.569927Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"f1_score (5 emo) по колонке annotator_emo = 0.718 roc_auc_score =  0.8761457372133957\nf1_score (5 emo) по колонке speaker_emo   = 0.731 roc_auc_score =  0.905502759992634\nf1_score (3 emo) по колонке annotator_emo = 0.966 roc_auc_score =  0.9470148750107813\nf1_score (3 emo) по колонке speaker_emo   = 0.9 roc_auc_score =  0.8751866786978845\n","output_type":"stream"}]},{"cell_type":"code","source":"for emo, df in emos.items():\n    for name_col in ('annotator_emo', 'speaker_emo'):\n        print(f'{emo} по колонке {name_col:<13}:')\n        print(classification_report(df[name_col], df['pred'], zero_division=0))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T15:33:10.985241Z","iopub.execute_input":"2023-09-10T15:33:10.985944Z","iopub.status.idle":"2023-09-10T15:33:14.625062Z","shell.execute_reply.started":"2023-09-10T15:33:10.985908Z","shell.execute_reply":"2023-09-10T15:33:14.623850Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"5 emo по колонке annotator_emo:\n              precision    recall  f1-score   support\n\n       angry       0.85      0.88      0.86      1278\n     neutral       0.74      0.83      0.78     10372\n       other       0.89      0.31      0.46       377\n    positive       0.83      0.85      0.84      1015\n         sad       0.60      0.48      0.54      4944\n\n    accuracy                           0.73     17986\n   macro avg       0.78      0.67      0.70     17986\nweighted avg       0.72      0.73      0.72     17986\n\n5 emo по колонке speaker_emo  :\n              precision    recall  f1-score   support\n\n       angry       0.92      0.60      0.73      2019\n     neutral       0.67      0.93      0.78      8320\n       other       0.00      0.00      0.00         0\n    positive       0.88      0.57      0.69      1594\n         sad       0.85      0.56      0.68      6053\n\n    accuracy                           0.74     17986\n   macro avg       0.66      0.53      0.57     17986\nweighted avg       0.78      0.74      0.73     17986\n\n3 emo по колонке annotator_emo:\n              precision    recall  f1-score   support\n\n       angry       0.85      0.88      0.86      1278\n     neutral       0.98      0.98      0.98     15693\n    positive       0.83      0.85      0.84      1015\n\n    accuracy                           0.97     17986\n   macro avg       0.89      0.90      0.90     17986\nweighted avg       0.97      0.97      0.97     17986\n\n3 emo по колонке speaker_emo  :\n              precision    recall  f1-score   support\n\n       angry       0.92      0.60      0.73      2019\n     neutral       0.91      0.99      0.95     14373\n    positive       0.88      0.57      0.69      1594\n\n    accuracy                           0.91     17986\n   macro avg       0.90      0.72      0.79     17986\nweighted avg       0.91      0.91      0.90     17986\n\n","output_type":"stream"}]}]}